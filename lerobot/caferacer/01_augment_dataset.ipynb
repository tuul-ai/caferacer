{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First cell - Setup paths\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Setup paths as before\n",
    "notebook_dir = os.path.dirname('__file__')\n",
    "lerobot_root = os.path.abspath(os.path.join(notebook_dir, '../..'))\n",
    "sys.path.append(lerobot_root)\n",
    "os.chdir(lerobot_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Optional, Dict, Union, Tuple\n",
    "\n",
    "from pathlib import Path\n",
    "import modal\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset\n",
    "from lerobot.caferacer.scripts.image_utils import reorder_tensor_dimensions, tensor_to_pil, display_images\n",
    "from lerobot.caferacer.scripts.aug_utils import flip_frame, apply_color, get_mask\n",
    "from lerobot.caferacer.scripts.gemini_utils import parse_json\n",
    "from lerobot.caferacer.scripts.inpaint_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#episodes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "repo_id = \"shreyasgite/so100_base_left\"\n",
    "#repo_id0 = \"shreyasgite/so100_base_env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsam = modal.Function.lookup(\"grounded-sam\",\"GroundedSam.run\", environment_name='prod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(repo_id, dataset0, gsam, GPU_POOR=True, DATA_AUG=None, create_new=False, batch_size=10):\n",
    "\n",
    "    if create_new:\n",
    "        dataset = LeRobotDataset.create(\n",
    "            repo_id,\n",
    "            fps=dataset0.fps,\n",
    "            robot_type=dataset0.meta.robot_type,\n",
    "            features=dataset0.features,\n",
    "            use_videos=len(dataset0.meta.video_keys) > 0, \n",
    "            image_writer_threads=8)\n",
    "    else:\n",
    "        dataset = LeRobotDataset(repo_id)\n",
    "        dataset.start_image_writer(num_threads=8)\n",
    "        \n",
    "    num_episodes = dataset0.num_episodes\n",
    "    image_keys = [key for key in dataset0[0].keys() if key.startswith(\"observation.images.\")]\n",
    "    \n",
    "    for batch_start in range(0, num_episodes, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, num_episodes)\n",
    "        print(f\"Processing episodes {batch_start} to {batch_end}\")\n",
    "\n",
    "        for ep_idx in range(batch_start, batch_end):\n",
    "            print(f\"Processing episode {ep_idx}\")\n",
    "            \n",
    "            # Get frame indices for this episode\n",
    "            from_idx = dataset0.episode_data_index[\"from\"][ep_idx].item()\n",
    "            to_idx = dataset0.episode_data_index[\"to\"][ep_idx].item()\n",
    "            print(f\"Processing frames {from_idx} to {to_idx}\")\n",
    "\n",
    "            # Process frames\n",
    "            for frame_idx in range(from_idx, to_idx):\n",
    "                obs = {}\n",
    "                frame_data = dataset0[frame_idx]\n",
    "                for key in image_keys:\n",
    "                    obs[key] = reorder_tensor_dimensions(frame_data[key])\n",
    "                obs['observation.state'] = frame_data['observation.state']\n",
    "                action = {\"action\": frame_data['action']}\n",
    "                \n",
    "                if DATA_AUG is not None:\n",
    "                    if 'inpaint_distractions' in DATA_AUG:\n",
    "                        object = DATA_AUG['inpaint_distractions']['objects']\n",
    "                        if frame_idx == from_idx: source_top_im, source_front_im, top_im_msk, front_im_msk = get_inpaint_object(gsam, obs, object)\n",
    "                        obs = create_inpainted_frame(obs, source_top_im, source_front_im, top_im_msk, front_im_msk)\n",
    "                    \n",
    "                    if 'flip_frame' in DATA_AUG:\n",
    "                        obs, action = flip_frame(obs, action, image_keys)\n",
    "                    \n",
    "                    if 'change_color' in DATA_AUG:\n",
    "                        if GPU_POOR: \n",
    "                            if frame_idx == from_idx:  mask = get_mask(gsam, obs, image_keys, object=DATA_AUG['change_color']['object'])\n",
    "                            elif frame_idx == from_idx + (8 * 30): mask = get_mask(gsam, obs, image_keys, object=DATA_AUG['change_color']['object'])\n",
    "                            elif frame_idx == from_idx + (10 * 30): mask = get_mask(gsam, obs, image_keys, object=DATA_AUG['change_color']['object'])\n",
    "                        else: mask = get_mask(gsam, obs, image_keys)\n",
    "                        target_color = DATA_AUG['change_color']['target_color']\n",
    "                        obs = apply_color(obs, mask, image_keys, target_color=target_color)\n",
    "\n",
    "                single_task = \"Grasp the lego brick and drop it in the Yellow Container.\"\n",
    "                frame = {**obs, **action, \"task\": single_task}\n",
    "                dataset.add_frame(frame)\n",
    "                \n",
    "            print(f\"Saving episode {ep_idx}\")\n",
    "            dataset.save_episode()\n",
    "            \n",
    "        gc.collect()\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_AUG = {'flip_frame': True, 'change_color': {'object': 'blue container', 'target_color': 'yellow'}, 'inpaint_distractions': {'objects': 'rubik cube'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base = LeRobotDataset(repo_id)\n",
    "dataset = create_dataset(repo_id, dataset_base, gsam, DATA_AUG=DATA_AUG)\n",
    "#dataset.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caferacer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
