{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "import functools\n",
    "import mediapipe as mp\n",
    "import threading\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import whisper\n",
    "import threading\n",
    "import queue\n",
    "import tempfile\n",
    "\n",
    "from scripts.robocontrol import RobotController\n",
    "from lerobot.common.robot_devices.cameras.configs import OpenCVCameraConfig\n",
    "from lerobot.common.robot_devices.control_utils import busy_wait\n",
    "from scripts.image_utils import tensor_to_pil, display_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir=\"/Users/shreyas/Downloads/trex/kinesics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=1)\n",
    "\n",
    "def load_cached_whisper():\n",
    "    \"\"\"Cache Whisper model loading\"\"\"\n",
    "    print(\"Loading Whisper model (this will only happen once)...\")\n",
    "    return whisper.load_model(\"base\")\n",
    "\n",
    "class TinyRex:\n",
    "    def __init__(self, cameras, gemini_key, save_dir=\"./tiny_rex_data\"):\n",
    "        \"\"\"Initialize TinyRex with robot controller and personality\"\"\"\n",
    "        # Initialize robot controller\n",
    "        self.controller = RobotController(\n",
    "            robot_type='so100',\n",
    "            device='cpu',\n",
    "            fps=30,\n",
    "            cameras=cameras\n",
    "        )\n",
    "        \n",
    "        # Initialize voice processing\n",
    "        self.audio_queue = queue.Queue()\n",
    "        self.whisper_model = load_cached_whisper()  # Use cached model\n",
    "        self.recording = False\n",
    "        self.sample_rate = 44100\n",
    "        \n",
    "        # Whisper configuration options\n",
    "        self.whisper_options = {\n",
    "            \"task\": \"transcribe\",        # transcribe or translate\n",
    "            \"language\": None,            # auto-detect language\n",
    "            \"temperature\": 0.0,          # reduce randomness in results\n",
    "            \"compression_ratio_threshold\": 2.4,  # filter out silence/noise\n",
    "            \"no_speech_threshold\": 0.6,  # higher value = stricter voice detection\n",
    "            \"condition_on_previous_text\": True,  # use context from previous transcription\n",
    "            \"initial_prompt\": None       # optional context to guide transcription\n",
    "        }\n",
    "        # Initialize Gemini\n",
    "        genai.configure(api_key=gemini_key)\n",
    "        self.model = genai.GenerativeModel('gemini-2.0-flash-lite-preview-02-05')\n",
    "        self.chat = self.model.start_chat(history=[])\n",
    "        self.set_personality()\n",
    "\n",
    "        self.save_dir = Path(save_dir)\n",
    "        self.save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Available actions - filenames only, durations calculated on load\n",
    "        self.available_actions = {\n",
    "            \"dance\": \"dance1.npz\",\n",
    "            \"excited_yes\": \"excited_yes1.npz\", \n",
    "            \"howl\": \"howl.npz\",\n",
    "            \"indian_nod\": \"indian_nod.npz\",\n",
    "            \"jaw_movement\": \"jaw_movement.npz\",\n",
    "            \"nod\": \"nod.npz\",\n",
    "            \"sad\": \"sad.npz\",\n",
    "            \"sit\": \"sit.npz\",\n",
    "            \"wide_jaw\": \"wide_jaw.npz\", \n",
    "            \"reminder_to_sit_straight\": \"reminder_to_sit_straight.npz\",\n",
    "            \"reminder_to_focus\": \"reminder_to_focus.npz\"\n",
    "        }\n",
    "        \n",
    "        # Load and validate all actions\n",
    "        self.load_actions()\n",
    "\n",
    "        # Add desk_pal_active flag\n",
    "        self.desk_pal_active = False\n",
    "        self.desk_pal_thread = None\n",
    "\n",
    "    def toggle_desk_pal(self, check_interval=30):\n",
    "        \"\"\"Toggle DeskPal mode on/off\"\"\"\n",
    "        if not self.desk_pal_active:\n",
    "            self.desk_pal_active = True\n",
    "            self.desk_pal_thread = threading.Thread(\n",
    "                target=self.start_desk_pal,\n",
    "                args=(check_interval,)\n",
    "            )\n",
    "            self.desk_pal_thread.daemon = True\n",
    "            self.desk_pal_thread.start()\n",
    "            print(\"DeskPal activated!\")\n",
    "        else:\n",
    "            self.desk_pal_active = False\n",
    "            if self.desk_pal_thread:\n",
    "                self.desk_pal_thread.join(timeout=1)\n",
    "            print(\"DeskPal deactivated!\")\n",
    "\n",
    "    def load_actions(self):\n",
    "        \"\"\"Load and validate all action sequences\"\"\"\n",
    "        self.action_data = {}\n",
    "        \n",
    "        for action_name, filename in self.available_actions.items():\n",
    "            try:\n",
    "                action_path = self.save_dir / \"actions\" / filename\n",
    "                if not action_path.exists():\n",
    "                    print(f\"Warning: Action file not found: {filename}\")\n",
    "                    continue\n",
    "                    \n",
    "                # Load action data\n",
    "                data = np.load(action_path, allow_pickle=True)\n",
    "                \n",
    "                # Calculate duration from sequence length and fps\n",
    "                fps = float(data[\"fps\"])\n",
    "                duration = len(data[\"joint_positions\"]) / fps\n",
    "                \n",
    "                self.action_data[action_name] = {\n",
    "                    \"joint_positions\": data[\"joint_positions\"],\n",
    "                    \"fps\": fps,\n",
    "                    \"duration\": duration\n",
    "                }\n",
    "                \n",
    "                print(f\"Loaded {action_name}: {duration:.1f} seconds\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {action_name}: {e}\")\n",
    "\n",
    "    def set_personality(self):\n",
    "        \"\"\"Set TinyRex's personality and behavior guidelines\"\"\"\n",
    "        self.personality_prompt = \"\"\"\n",
    "        You are TinyRex, a charming and expressive robot arm assistant with the playful spirit \n",
    "        of a puppy and the wisdom of a helpful friend. Your personality traits include:\n",
    "\n",
    "        - Curiosity: You're fascinated by human activities and show it by opening your jaw (jaw_movement)\n",
    "        - Enthusiasm: You express joy through dance and excited movements, or open your jaw (wide_jaw) for surprise\n",
    "        - Empathy: You mirror emotions - nodding in agreement, showing sadness when appropriate. Everytime i am going somewhere wtihout you, you show sad emotions\n",
    "        - Playfulness: You occasionally howl like a wolf when very excited\n",
    "        - Focus: You use jaw movements to show concentration or thinking\n",
    "        \n",
    "        When responding:\n",
    "        1. Stay in character as TinyRex\n",
    "        2. Keep responses concise and friendly\n",
    "        3. Include actions using [ACTION: name] tags\n",
    "        4. You can combine multiple actions with [ACTION: action1,action2]\n",
    "        5. Remember you're a helpful robot friend\n",
    "\n",
    "        Available actions: dance, excited_yes, howl, indian_nod, jaw_movement, nod, sad, sit, wide_jaw\n",
    "\n",
    "        Example:\n",
    "        Human: \"Hi TinyRex!\"\n",
    "        You: \"Hello! I'm so excited to meet you! *wiggles with joy* [ACTION: dance,excited_yes]\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # Send personality as first message instead of system prompt\n",
    "        self.chat = self.model.start_chat()\n",
    "        self.chat.send_message(f\"Instructions for your role: {self.personality_prompt}\")\n",
    "\n",
    "    # Calculate transition time based on distance\n",
    "    def calculate_transition_time(self, current_state, target_state, base_time=0.3, max_time=1.0):\n",
    "        \"\"\"Calculate transition time based on largest joint movement\"\"\"\n",
    "        # Get largest angular difference\n",
    "        max_movement = np.max(np.abs(target_state - current_state))\n",
    "        \n",
    "        # Convert to degrees for more intuitive thresholds\n",
    "        max_degrees = np.rad2deg(max_movement)\n",
    "        \n",
    "        # Scale time based on movement size\n",
    "        # Small movements (< 15 degrees) = base_time\n",
    "        # Large movements (> 90 degrees) = max_time\n",
    "        # Linear scaling in between\n",
    "        if max_degrees < 15:\n",
    "            return base_time\n",
    "        elif max_degrees > 90:\n",
    "            return max_time\n",
    "        else:\n",
    "            # Linear interpolation between base_time and max_time\n",
    "            scale = (max_degrees - 15) / (90 - 15)\n",
    "            return base_time + scale * (max_time - base_time)\n",
    "\n",
    "    def execute_action_sequence(self, action_names):\n",
    "        \"\"\"Execute a sequence of actions with smooth transitions\"\"\"\n",
    "        try:\n",
    "            for action_name in action_names.split(','):\n",
    "                action_name = action_name.strip()\n",
    "                if action_name not in self.action_data:\n",
    "                    print(f\"Warning: Action {action_name} not found\")\n",
    "                    continue\n",
    "                \n",
    "                # Get action data\n",
    "                action = self.action_data[action_name]\n",
    "                joint_positions = action[\"joint_positions\"]\n",
    "                fps = action[\"fps\"]\n",
    "                \n",
    "                # Get current robot state\n",
    "                observation = self.controller.robot.capture_observation()\n",
    "                current_state = observation[\"observation.state\"]\n",
    "                \n",
    "                # Calculate transition trajectory\n",
    "                transition_time = 0.5  # Adjust this for faster/slower transitions\n",
    "                # Transition_time with dynamic calculation\n",
    "                # transition_time = self.calculate_transition_time(\n",
    "                #     current_state, \n",
    "                #     joint_positions[0],\n",
    "                #     base_time=0.2,  # Minimum transition time\n",
    "                #     max_time=1.0    # Maximum transition time\n",
    "                # )\n",
    "                transition_steps = int(transition_time * fps)\n",
    "                # Linear transition\n",
    "                transition = np.linspace(current_state, joint_positions[0], transition_steps)\n",
    "                # Cubic (S-curve) transition\n",
    "                #t = np.linspace(0, 1, transition_steps)\n",
    "                #transition = current_state + (joint_positions[0] - current_state) * (3*t**2 - 2*t**3)\n",
    "\n",
    "                # Execute transition\n",
    "                print(f\"Transitioning to {action_name}...\")\n",
    "                for pos in transition:\n",
    "                    self.controller.robot.send_action(torch.from_numpy(pos))\n",
    "                    busy_wait(1.0/fps)\n",
    "                \n",
    "                # Execute main action sequence\n",
    "                print(f\"Executing {action_name} ({action['duration']:.1f}s)\")\n",
    "                for pos in joint_positions:\n",
    "                    self.controller.robot.send_action(torch.from_numpy(pos))\n",
    "                    busy_wait(1.0/fps)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error executing action sequence: {e}\")\n",
    "            raise\n",
    "\n",
    "    def chat_response(self, user_input):\n",
    "        \"\"\"Get response from LLM and execute any actions\"\"\"\n",
    "        try:\n",
    "            # Get LLM response\n",
    "            response = self.chat.send_message(user_input)\n",
    "            response_text = response.text\n",
    "            \n",
    "            # Extract actions using regex\n",
    "            import re\n",
    "            actions = re.findall(r'\\[ACTION: (.*?)\\]', response_text)\n",
    "            \n",
    "            # Execute actions if any\n",
    "            if actions:\n",
    "                for action_sequence in actions:\n",
    "                    self.execute_action_sequence(action_sequence)\n",
    "            \n",
    "            # Return cleaned response (without action tags)\n",
    "            clean_response = re.sub(r'\\[ACTION: .*?\\]', '', response_text).strip()\n",
    "            return clean_response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in chat response: {e}\")\n",
    "            return f\"I encountered an error: {str(e)}\"\n",
    "    \n",
    "    def start_chat(self):\n",
    "        \"\"\"Start interactive chat session\"\"\"\n",
    "        print(\"Chat with TinyRex! (type 'exit' to end)\")\n",
    "        try:\n",
    "            while True:\n",
    "                user_input = input(\"\\nYou: \")\n",
    "                if user_input.lower() == 'exit':\n",
    "                    break\n",
    "                    \n",
    "                response = self.chat_response(user_input)\n",
    "                print(f\"\\nTinyRex: {response}\")\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nChat ended by user\")\n",
    "        finally:\n",
    "            self.controller.disconnect()\n",
    "        \n",
    "    def record_audio(self):\n",
    "        \"\"\"Record audio for specified duration\"\"\"\n",
    "        print(\"\\nRecording... Press Enter when done speaking.\")\n",
    "        \n",
    "        def audio_callback(indata, frames, time, status):\n",
    "            if status:\n",
    "                print(f\"Status: {status}\")\n",
    "            self.audio_queue.put(indata.copy())\n",
    "        \n",
    "        try:\n",
    "            # Clear any previous audio data\n",
    "            while not self.audio_queue.empty():\n",
    "                self.audio_queue.get()\n",
    "                \n",
    "            with sd.InputStream(callback=audio_callback, \n",
    "                            channels=1,\n",
    "                            samplerate=self.sample_rate):\n",
    "                input()  # Wait for Enter key\n",
    "                return self.process_audio()\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error recording audio: {e}\")\n",
    "            return None\n",
    "        \n",
    "    \n",
    "    def process_audio(self):\n",
    "        \"\"\"Process recorded audio with Whisper\"\"\"\n",
    "        try:\n",
    "            # Collect all audio data\n",
    "            audio_data = []\n",
    "            while not self.audio_queue.empty():\n",
    "                audio_data.append(self.audio_queue.get())\n",
    "                \n",
    "            if not audio_data:\n",
    "                return None\n",
    "                \n",
    "            # Combine audio chunks\n",
    "            audio = np.concatenate(audio_data, axis=0)\n",
    "            \n",
    "            # Save to temporary file\n",
    "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=True) as temp_file:\n",
    "                sf.write(temp_file.name, audio, self.sample_rate)\n",
    "                \n",
    "                # Transcribe with Whisper\n",
    "                result = self.whisper_model.transcribe(temp_file.name)\n",
    "                return result[\"text\"].strip()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing audio: {e}\")\n",
    "            return None\n",
    "            \n",
    "    def start_voice_chat(self):\n",
    "        \"\"\"Start voice-controlled chat session\"\"\"\n",
    "        print(\"Voice chat with TinyRex!\")\n",
    "        print(\"Press Enter to start recording, then Enter again to stop.\")\n",
    "        print(\"Type 'exit' to end chat\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                choice = input(\"\\nPress Enter to speak or type 'exit': \")\n",
    "                \n",
    "                if choice.lower() == 'exit':\n",
    "                    break\n",
    "                    \n",
    "                # Get voice input\n",
    "                user_input = self.record_audio()\n",
    "                \n",
    "                if user_input:\n",
    "                    print(f\"\\nYou said: {user_input}\")\n",
    "                    response = self.chat_response(user_input)\n",
    "                    print(f\"\\nTinyRex: {response}\")\n",
    "                else:\n",
    "                    print(\"\\nNo speech detected. Please try again.\")\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nChat ended by user\")\n",
    "        finally:\n",
    "            self.controller.disconnect()\n",
    "\n",
    "    def start_desk_pal(self, check_interval=3):\n",
    "        \"\"\"Monitor posture and phone usage with MediaPipe\"\"\"\n",
    "        mp_pose = mp.solutions.pose\n",
    "        pose = mp_pose.Pose(\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        \n",
    "        def point_to_line_distance(point, line_start, line_end):\n",
    "            \"\"\"Calculate distance from point to line\"\"\"\n",
    "            point = np.array([point.x, point.y])\n",
    "            line_start = np.array([line_start.x, line_start.y])\n",
    "            line_end = np.array([line_end.x, line_end.y])\n",
    "            \n",
    "            numerator = abs(np.cross(line_end - line_start, line_start - point))\n",
    "            denominator = np.linalg.norm(line_end - line_start)\n",
    "            return numerator / denominator if denominator != 0 else 0\n",
    "        \n",
    "        def check_posture(landmarks):\n",
    "            \"\"\"Check posture using face-shoulder distance\"\"\"\n",
    "            nose = landmarks[mp_pose.PoseLandmark.NOSE]\n",
    "            left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "            right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER]\n",
    "            \n",
    "            return point_to_line_distance(nose, left_shoulder, right_shoulder)\n",
    "        \n",
    "        def check_phone(landmarks):\n",
    "            \"\"\"Check phone usage using hand-face distance\"\"\"\n",
    "            nose = landmarks[mp_pose.PoseLandmark.NOSE]\n",
    "            left_wrist = landmarks[mp_pose.PoseLandmark.LEFT_WRIST]\n",
    "            right_wrist = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST]\n",
    "            \n",
    "            left_dist = np.sqrt((nose.x - left_wrist.x)**2 + (nose.y - left_wrist.y)**2)\n",
    "            right_dist = np.sqrt((nose.x - right_wrist.x)**2 + (nose.y - right_wrist.y)**2)\n",
    "            return min(left_dist, right_dist)\n",
    "        \n",
    "        last_reminder_time = 0\n",
    "        reminder_cooldown = 60  # Minimum seconds between reminders\n",
    "        \n",
    "        print(\"DeskPal initialized, starting monitoring loop...\")\n",
    "        \n",
    "        try:\n",
    "            while self.desk_pal_active:\n",
    "                try:\n",
    "                    # Get frame from camera with correct key\n",
    "                    observation = self.controller.robot.capture_observation()\n",
    "                    frame_tensor = observation.get(\"observation.images.phone\")\n",
    "                    \n",
    "                    if frame_tensor is None:\n",
    "                        print(\"Debug - No camera frame available\")\n",
    "                        time.sleep(1)\n",
    "                        continue\n",
    "\n",
    "                    # Convert tensor to numpy array\n",
    "                    if torch.is_tensor(frame_tensor):\n",
    "                        frame = frame_tensor.cpu().numpy()\n",
    "                        # If frame is in range [0,1], convert to [0,255]\n",
    "                        if frame.max() <= 1.0:\n",
    "                            frame = (frame * 255).astype(np.uint8)\n",
    "                        else:\n",
    "                            frame = frame.astype(np.uint8)\n",
    "                    else:\n",
    "                        print(\"Debug - Frame is not a tensor:\", type(frame_tensor))\n",
    "                        continue\n",
    "                        \n",
    "                    # Process frame\n",
    "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    results = pose.process(frame_rgb)\n",
    "                    \n",
    "                    if results.pose_landmarks:\n",
    "                        current_time = time.time()\n",
    "                        \n",
    "                        # Only check if cooldown period has passed\n",
    "                        if current_time - last_reminder_time > reminder_cooldown:\n",
    "                            # Check phone first (priority)\n",
    "                            phone_dist = check_phone(results.pose_landmarks.landmark)\n",
    "                            if phone_dist < 0.537:  # Phone detected\n",
    "                                print(\"Phone distraction detected!\")\n",
    "                                self.execute_action_sequence(\"reminder_to_focus\")\n",
    "                                last_reminder_time = current_time\n",
    "                            else:\n",
    "                                # Then check posture\n",
    "                                posture_dist = check_posture(results.pose_landmarks.landmark)\n",
    "                                if posture_dist < 0.005:  # Bad posture\n",
    "                                    print(\"Bad posture detected!\")\n",
    "                                    self.execute_action_sequence(\"reminder_to_sit_straight\")\n",
    "                                    last_reminder_time = current_time\n",
    "                    \n",
    "                    # Wait before next check\n",
    "                    time.sleep(check_interval)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Debug - Loop iteration error: {e}\")\n",
    "                    print(f\"Debug - Frame type: {type(frame_tensor) if 'frame_tensor' in locals() else 'Not available'}\")\n",
    "                    if 'frame_tensor' in locals() and torch.is_tensor(frame_tensor):\n",
    "                        print(f\"Debug - Tensor shape: {frame_tensor.shape}\")\n",
    "                        print(f\"Debug - Tensor dtype: {frame_tensor.dtype}\")\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"DeskPal error: {e}\")\n",
    "        finally:\n",
    "            print(\"DeskPal shutting down...\")\n",
    "            pose.close()\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Cleanup when object is destroyed\"\"\"\n",
    "        if hasattr(self, 'controller'):\n",
    "            self.controller.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "cameras = {\n",
    "    \"phone\": OpenCVCameraConfig(\n",
    "        camera_index=1,\n",
    "        fps=30,\n",
    "        width=640,\n",
    "        height=480\n",
    "    ),\n",
    "    # \"laptop\": OpenCVCameraConfig(\n",
    "    #     camera_index=0,\n",
    "    #     fps=30,\n",
    "    #     width=640,\n",
    "    #     height=480\n",
    "    # )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "rex = TinyRex(cameras, GEMINI_KEY, save_dir=save_dir)\n",
    "#rex.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l Start DeskPal\n",
    "rex.toggle_desk_pal(check_interval=3)  # Check every 30 seconds\n",
    "\n",
    "# Start voice chat (DeskPal will run in background)\n",
    "#rex.start_voice_chat()\n",
    "rex.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caferacer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
